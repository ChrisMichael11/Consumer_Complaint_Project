{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import EDA libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datafiles from Consumer Finance Protection Bureau API\n",
    "#### Consumer_Complaints.csv (full dataset)\n",
    "#### Consumer_Complaints_with_Consumer_Complaint_Narratives.csv (with text complaints only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../data/Consumer_Complaints.csv')\n",
    "df = pd.read_csv('../data/Consumer_Complaints_with_Consumer_Complaint_Narratives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.info() #596096 entries, 18 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info() #84466 entries, 18 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkout each column, just using \"df\" for now to get the whole scope of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Recieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Date received'].value_counts(dropna=False)\n",
    "# df['Date received'].value_counts(dropna=False).shape #(1688,)\n",
    "# put date in datetime format\n",
    "df['Date received']=pd.DatetimeIndex(df['Date received'],format='%m/%d/%Y').date\n",
    "\n",
    "print df['Date received'].min()\n",
    "print df['Date received'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Product'].value_counts(dropna=False)\n",
    "# df['Product'].value_counts(dropna=False).shape #(11,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['Sub-product'].value_counts(dropna=False)\n",
    "# df['Sub-product'].value_counts(dropna=False).shape #(46,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Issue'].value_counts(dropna=False)\n",
    "df['Issue'].value_counts(dropna=False).shape #(90,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Sub-issue'].value_counts()\n",
    "df['Sub-issue'].value_counts().shape   #(64,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumer complaint narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer complaint narrative'].value_counts(dropna=False)\n",
    "df['Consumer complaint narrative'].value_counts(dropna=False).shape   #(83048,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company public response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company public response'].value_counts(dropna=False)\n",
    "df['Company public response'].value_counts(dropna=False).shape   #(11,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company'].value_counts(dropna=False)\n",
    "df['Company'].value_counts(dropna=False).shape #(2460,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['State'].value_counts(dropna=False)\n",
    "df['State'].value_counts(dropna=False).shape #(62,)\n",
    "\n",
    "# Use pyzipcode to find missing zipcodes\n",
    "# https://pypi.python.org/pypi/pyzipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ZIP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['ZIP code'].value_counts(dropna=False)\n",
    "df['ZIP code'].value_counts(dropna=False).shape #(920,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Tags'].value_counts(dropna=False)\n",
    "df['Tags'].value_counts(dropna=False).shape   #(4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumer consent provided?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer consent provided?'].value_counts(dropna=False)\n",
    "df['Consumer consent provided?'].value_counts(dropna=False).shape #(1,)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitted via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Submitted via'].value_counts()\n",
    "df['Submitted via'].value_counts().shape   #(1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date sent to company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df['Date sent to company'].value_counts(dropna=False)\n",
    "# df['Date sent to company'].value_counts(dropna=False).shape #(1637,)\n",
    "# put date in datetime format\n",
    "df['Date sent to company']=pd.DatetimeIndex(df['Date sent to company'],format='%m/%d/%Y').date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company response to consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company response to consumer'].value_counts(dropna=False)\n",
    "# df['Company response to consumer'].value_counts(dropna=False).shape #(5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timely Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Timely response?'].value_counts(dropna=False)\n",
    "# df['Timely response?'].value_counts(dropna=False).shape  #(2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumer disputed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer disputed?'].value_counts(dropna=False)\n",
    "# df['Consumer disputed?'].value_counts(dropna=False).shape  #(3,)df['Consumer consent provided?'].value_counts()\n",
    "# df['Consumer consent provided?'].value_counts().shape   #(1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complaint ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['Complaint ID'].value_counts(dropna=False)\n",
    "# df['Complaint ID'].value_counts().shape   #(84466,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1 = pd.crosstab(df['Product'], df['Consumer disputed?'])\n",
    "p1.plot(kind='bar', figsize=(10,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p2 = pd.crosstab(df['Product'], df['Submitted via'])\n",
    "p2.plot(kind='bar', figsize=(10,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p3 = pd.crosstab(df['Product'], df['Submitted via'])\n",
    "p3.plot(kind='bar', figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p4 = pd.crosstab(df['Company response to consumer'], df['Consumer disputed?'])\n",
    "p4.plot(kind='bar', figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p5 = pd.crosstab(df['Product'], df['Consumer disputed?'])\n",
    "p5.plot(kind='bar',figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p6 = pd.crosstab(df['Product'], df['Tags'])\n",
    "p6.plot(kind='bar',figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p7 = pd.crosstab(df['Submitted via'], df['Tags'])\n",
    "p7.plot(kind='bar',figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p8 = pd.crosstab(df['Consumer disputed?'], df['Tags'])\n",
    "p8.plot(kind='bar',figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p9 = pd.crosstab(df['Date sent to company'], df['Submitted via'][5])\n",
    "# p9\n",
    "# p9.plot(kind='bar',figsize=(10,8))\n",
    "#  Crappy plot, but shows that web is on the increase in full set of data, using text features it is just a mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# p10 = pd.crosstab(df['Product'], df['Consumer complaint narrative'])\n",
    "# p10.plot(kind='bar',figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "productCountFrame = df.groupby(\"Product\")[\"Consumer complaint narrative\"].count()\n",
    "#from pylab import *\n",
    "#val = 3+10*rand(5)    # the bar lengths\n",
    "pos = np.arange(productCountFrame.shape[0])+.5    # the bar centers on the y axis\n",
    "\n",
    "plt.barh(pos,productCountFrame, align='center')\n",
    "plt.yticks(pos,productCountFrame.index)\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel(\"Product Type\")\n",
    "plt.title('Distribution of Product Type')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/mmrosenb/d/cfpb/us-consumer-finance-complaints/language-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Product'].fillna('Not Provided', inplace=True)\n",
    "df['Sub-product'].fillna('Not Provided', inplace=True)\n",
    "df['Sub-issue'].fillna('Not Provided', inplace=True)\n",
    "df['Issue'].fillna('Not Provided', inplace=True)\n",
    "df['Consumer complaint narrative'].fillna('Not Provided', inplace=True)\n",
    "df['Company public response'].fillna('Not Provided', inplace=True)\n",
    "df['Company'].fillna('Not Provided', inplace=True)\n",
    "df['State'].fillna('Not Provided', inplace=True)\n",
    "df['ZIP code'].fillna('Not Provided', inplace=True)\n",
    "df['Tags'].fillna('Not Provided', inplace=True)\n",
    "df['Consumer consent provided?'].fillna('Not Provided', inplace=True)\n",
    "df['Submitted via'].fillna('Not Provided',inplace=True) \n",
    "df['Consumer disputed?'].fillna('Not Provided', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to modify 'Consumer consent provided?' to have binary-ish response.\n",
    "#### Assume 'Consent withdrawn' and 'Other' are equivalent to 'Consent not provided'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer consent provided?'].value_counts()\n",
    "#For a reminder of what is in there - All full with web/text submittals, different for full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Consumer consent provided?'] = df['Consumer consent provided?'].apply(lambda x: \n",
    "        'Consent not provided' if x=='Other' or x=='Consent withdrawn'\n",
    "         or x=='Not Provided' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer disputed?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to modify \"Consumer disputed?\" to have binary-ish response\n",
    "#### Assume \"Not Provided\" = \"No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Consumer disputed?'] = df['Consumer disputed?'].apply(lambda x: \n",
    "        'No' if x=='Not Provided' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer disputed?'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crosstab of consent provided vs disputed\n",
    "consent_provided_v_disputed = pd.crosstab(df['Consumer consent provided?'], df['Consumer disputed?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "consent_provided_v_disputed\n",
    "#  Print crosstab table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Convert to 1/0 for labels binary response\n",
    "replace_Y_N_to_1_zero = {'Yes': True, 'No':False}\n",
    "df['Consumer disputed?'] = df['Consumer disputed?'].apply(lambda x: replace_Y_N_to_1_zero[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Consumer disputed?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing state zipcodes using pyzipcode (link above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyzipcode import ZipCodeDatabase\n",
    "zipcode=ZipCodeDatabase()\n",
    "\n",
    "for i in df[pd.isnull(df['State'])&pd.notnull(df['ZIP code'])].index:\n",
    "    try:\n",
    "        df['State'][i]=str(zipcode[df['ZIP code'][i]].state)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check to see if all ZIP codes are filled\n",
    "\n",
    "Full data set has more missing info.  Step not needed for text data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[pd.isnull(df['State'])&pd.isnull(df['ZIP code'])].shape #4713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['State'].fillna('Not provided',inplace=True)\n",
    "df['ZIP code'].fillna('Not Provided',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[pd.isnull(df['State'])&pd.isnull(df['ZIP code'])].shape #0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering/Additional EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add count of company complaints (total) for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_company_complaints = df['Company'].value_counts()\n",
    "df['Count of Company Complaints'] = df['Company'].apply(lambda x: count_company_complaints[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create numerical date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['Recieved Year'] = df['Date received'].apply(lambda x: x.year)\n",
    "# df['Recieved Month'] = df['Date received'].apply(lambda x: x.month)\n",
    "# df['Recieved Day'] = df['Date received'].apply(lambda x: x.day)\n",
    "\n",
    "# df['Submitted Year'] = df['Date sent to company'].apply(lambda x: x.year)\n",
    "# df['Submitted Month'] = df['Date sent to company'].apply(lambda x: x.month)\n",
    "# df['Submitted Day'] = df['Date sent to company'].apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Label from \"Company response to consumer\".  Needs to be numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company response to consumer'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out \"Not Provided\"\n",
    "df = df[df['Consumer complaint narrative'] != 'Not Provided']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter out \"In progress\"\n",
    "df = df[df['Company response to consumer'] != 'In progress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company response to consumer'].value_counts(dropna=False)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dict to repalce 7 leftover categories with numbers for classificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For use with text df\n",
    "cust_resp_dict ={'Closed':0,\n",
    "                 'Untimely response':0,\n",
    "                 'Closed with explanation':1,\n",
    "                 'Closed with non-monetary relief':2,\n",
    "                 'Closed with monetary relief':2}\n",
    "\n",
    "# # For use with full text df\n",
    "# cust_resp_dict ={'Closed':0,\n",
    "#                  'Untimely response':0,\n",
    "#                  'Closed without relief':1,\n",
    "#                  'Closed with explanation':1,\n",
    "#                  'Closed with relief':2,\n",
    "#                  'Closed with non-monetary relief':2,\n",
    "#                  'Closed with monetary relief':2}\n",
    "# #  Trying as 1 and 0 insteand of 0, 1, 2 for more simple classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company response to consumer'] = df['Company response to consumer'].apply(lambda x: cust_resp_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Company response to consumer'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['Date received']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"model_data\" DF for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign categorical values numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_for_model=['Product', 'Sub-product','Issue','Sub-issue','Tags', 'State', 'Submitted via']\n",
    "\n",
    "for name in feature_for_model:\n",
    "    val ={}\n",
    "    i=0\n",
    "    for value in df[name].unique(): \n",
    "        val[value] = i\n",
    "        i+=1\n",
    "       \n",
    "    df[name] = df[name].apply(lambda x: val[x])\n",
    "    model_data[name] = df[name].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(model_data, alpha-0.2, figsize=99,9=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compl_v_resp = pd.crosstab(df['Count of Company Complaints'], df['Company response to consumer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compl_v_resp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compl_v_resp['Non-Relief Rate'] = (compl_v_resp[0] + compl_v_resp[1]) / (compl_v_resp[0] + compl_v_resp[1] + compl_v_resp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compl_v_resp['Relief Rate'] = compl_v_resp[2] / (compl_v_resp[0] + compl_v_resp[1] + compl_v_resp[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compl_v_resp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compl_v_resp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(compl_v_resp['Relief Rate'])\n",
    "plt.plot(compl_v_resp['Non-Relief Rate'])\n",
    "\n",
    "plt.xlim([0.0, 6000])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Count of Complaints')\n",
    "plt.ylabel('Relief/Non-Relief Rate')\n",
    "#plt.title()\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "# Looks bad using 1/0 for releif sorting...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_sent = df['Date sent to company'].apply(lambda x: x.day)\n",
    "month_sent = df['Date sent to company'].apply(lambda x: x.month)\n",
    "year_sent = df['Date sent to company'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_v_resp = pd.crosstab(month_sent, df['Company response to consumer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_v_resp['Non-Relief Rate'] = (month_v_resp[0] + month_v_resp[1]) / (month_v_resp[0] + month_v_resp[1] + month_v_resp[2])\n",
    "month_v_resp['Relief Rate'] = month_v_resp[2] / (month_v_resp[0] + month_v_resp[1] + month_v_resp[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_v_resp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(month_v_resp.index,month_v_resp['Relief Rate'])\n",
    "plt.plot(month_v_resp.index,month_v_resp['Non-Relief Rate'])\n",
    "\n",
    "plt.xlim([0.0, 12])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Relief/Non-Relief Rate')\n",
    "#plt.title('')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_v_resp = pd.crosstab(df['State'], df['Company response to consumer'])\n",
    "state_v_resp['Relief Rate'] = (state_v_resp[0] + state_v_resp[1]) / (state_v_resp[0] + state_v_resp[1] + state_v_resp[2])\n",
    "state_v_resp['Non-Relief Rate'] = state_v_resp[2] / (state_v_resp[0] + state_v_resp[1] + state_v_resp[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# state_v_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(state_v_resp.index,state_v_resp['Relief Rate'])\n",
    "plt.plot(state_v_resp.index,state_v_resp['Non-Relief Rate'])\n",
    "\n",
    "plt.xlim([0.0, 60])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Relief/Non-Relief Rate')\n",
    "# plt.title('')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Submitted via'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit_v_resp = pd.crosstab(df['Submitted via'], df['Company response to consumer'])\n",
    "submit_v_resp['Relief Rate'] = submit_v_resp[0] /(submit_v_resp[0] + submit_v_resp[1] + submit_v_resp[2])\n",
    "submit_v_resp['Non-Relief Rate'] = submit_v_resp[2] /(submit_v_resp[0] + submit_v_resp[1] + submit_v_resp[2])\n",
    "# DOESNT WORK HERE SILLY, you've got to submit via web to add a customer narrative, or get a text response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit_v_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10,8))\n",
    "# plt.plot(submit_v_resp.index,submit_v_resp['Relief Rate'])\n",
    "# plt.plot(submit_v_resp.index,submit_v_resp['Non-Relief Rate'])\n",
    "\n",
    "# plt.xlim([0.0, 60])\n",
    "# plt.ylim([0.0, 6])\n",
    "# plt.xlabel('Submitted via')\n",
    "# plt.ylabel('Relief/Non-Relief Rate')\n",
    "# # plt.title('')\n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICAL CHECKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Distribution of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = df['Company response to consumer'].value_counts()\n",
    "labels\n",
    "# 1    6449  # 76.34% 1 - Closed w/Explanation\n",
    "# 2    17032 # 20.11% 2 - Closed w/Relief, Closed w/non-monetary relief, Close w/monetary relief\n",
    "# 0     2936 # 3.48%  0 - Untimley Response, Closed w/o Relief, Closed\n",
    "\n",
    "# 'Closed':0,\n",
    "#                  'Untimely response':0,\n",
    "#                  'Closed without relief':0,\n",
    "#                  'Closed with explanation':1,\n",
    "#                  'Closed with relief':2,\n",
    "#                  'Closed with non-monetary relief':2,\n",
    "#                  'Closed with monetary relief':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, MaxAbsScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from scipy import interp\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = model_data.values\n",
    "y_start = df['Company response to consumer']\n",
    "y = label_binarize(y_start, classes = [0, 1, 2])\n",
    "n_classes = 2\n",
    "y_start.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using One v Rest classifier to predict each class against the other with NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, n_jobs=-1, class_weight='auto'))\n",
    "y_score = clf.fit(X_train, y_train).predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = clf.score(X_test, y_test)\n",
    "# accuracy = clf.accuracy()\n",
    "# Precision_Recall = clf.rec\n",
    "\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i],y_score[:, i],drop_intermediate=False)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "label = ['Closed w/o Relief', 'Closed w/relief']  #'Closed w/explaination',\n",
    "for i,v in enumerate(label):\n",
    "    plt.plot(fpr[i], tpr[i], label= v + ' (auc_area = {1:0.2f})'\n",
    "                                   ''.format(i, roc_auc[i]))\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity, Recall)')\n",
    "plt.title('ROC with non-text Features')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=750, n_jobs=-1, class_weight='auto')\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_importance(clf, X, max_features=10):\n",
    "    '''Plot Feature Importance'''\n",
    "    feature_importance = clf.feature_importances_\n",
    "    \n",
    "    # Make importances rel to max importance\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    \n",
    "    # Show only top XX features\n",
    "    pos = pos[-max_features:]\n",
    "    feature_importance = (feature_importance[sorted_idx])[-max_features:]\n",
    "    feature_names = (X.columns[sorted_idx])[-max_features:]\n",
    "    \n",
    "    plt.barh(pos, feature_importance, align='center')\n",
    "    plt.yticks(pos, feature_names)\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Non-Text Feature Importance')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_importance(rfc, model_data, max_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/Consumer_Complaints_with_Consumer_Complaint_Narratives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_data2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_for_model=['Product', 'Sub-product','Issue','Sub-issue','Tags', 'State', 'Submitted via']\n",
    "\n",
    "for name in feature_for_model:\n",
    "    val ={}\n",
    "    i=0\n",
    "    for value in df2[name].unique(): \n",
    "        val[value] = i\n",
    "        i+=1\n",
    "       \n",
    "    df2[name] = df2[name].apply(lambda x: val[x])\n",
    "    model_data2[name] = df2[name].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For use with text df\n",
    "cust_resp_dict ={'Closed':0,\n",
    "                 'Untimely response':0,\n",
    "                 'Closed with explanation':0,\n",
    "                 'Closed with non-monetary relief':1,\n",
    "                 'Closed with monetary relief':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['Company response to consumer'] = df2['Company response to consumer'].apply(lambda x: cust_resp_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['Company response to consumer'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2 = model_data.values\n",
    "y2 = df['Company response to consumer'].values\n",
    "y2 = label_binarize(y_start, classes = [0, 1])\n",
    "# n2_classes = 2\n",
    "# y2_start.shape\n",
    "y2 = y2.sum(axis=1)\n",
    "#  Need to sum y2 to make it a single column for use in LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X2_train)\n",
    "X2_train = scaler.transform(X2_train)\n",
    "X2_test = scaler.transform(X2_test)\n",
    "# X_train.shape\n",
    "y2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='auto')\n",
    "lr.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_probs = lr.predict_proba(X2_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_curve(probabilities, labels):\n",
    "    '''\n",
    "    INPUT: numpy array, numpy array\n",
    "    OUTPUT: list, list, list\n",
    "\n",
    "    Take a numpy array of the predicted probabilities and a numpy array of the\n",
    "    true labels.\n",
    "    Return the True Positive Rates, False Positive Rates and Thresholds for the\n",
    "    ROC curve.\n",
    "    '''\n",
    "\n",
    "    thresholds = np.sort(probabilities)\n",
    "\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "\n",
    "    num_positive_cases = sum(labels)\n",
    "    num_negative_cases = len(labels) - num_positive_cases\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # With this threshold, give the prediction of each instance\n",
    "        predicted_positive = probabilities >= threshold\n",
    "        # Calculate the number of correctly predicted positive cases\n",
    "        true_positives = np.sum(predicted_positive * labels)\n",
    "        # Calculate the number of incorrectly predicted positive cases\n",
    "        false_positives = np.sum(predicted_positive) - true_positives\n",
    "        # Calculate the True Positive Rate\n",
    "        tpr = true_positives / float(num_positive_cases)\n",
    "        # Calculate the False Positive Rate\n",
    "        fpr = false_positives / float(num_negative_cases)\n",
    "\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "    \n",
    "    return tprs, fprs, thresholds.tolist()\n",
    "\n",
    "def plot_roc(v_probs, y2_test, title, xlabel, ylabel):\n",
    "    # ROC\n",
    "    fig = plt.figure(figsize = (8,6))\n",
    "    tpr, fpr, thresholds = roc_curve(v_probs, y2_test)\n",
    "    \n",
    "    import sklearn.metrics as skm\n",
    "    auc = skm.roc_auc_score(y2_test, v_probs)\n",
    "\n",
    "    plt.hold(True)\n",
    "    plt.plot(fpr, tpr)\n",
    "\n",
    "    # 45 degree line\n",
    "    xx = np.linspace(0, 1.0, 20)\n",
    "    plt.plot(xx, xx, 'k--')\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(title+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_roc(v_probs, y2_test, \"ROC plot\", \"False Positive Rate (1 - Specificity)\", \n",
    "         \"True Positive Rate (Sensitivity, Recall)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skm.roc_auc_score(y2_test, v_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skm.recall_score(y2_test, lr.predict(X2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skm.precision_score(y2_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE TEXT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame()\n",
    "df_words_labels = pd.DataFrame()\n",
    "#df_txt = pd.read_csv('../data/Consumer_Complaints_with_Consumer_Complaint_Narratives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_words['Consumer complaint narrative'] = df['Consumer complaint narrative']\n",
    "df_words['Company response to customer'] = df['Company response to consumer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Try not removing XXXX's to see if leaving personal info (even though redacted) has effect\n",
    "# #  Remove XXX's in data where personal info has been removed\n",
    "# chars_to_remove = ['XX', 'XXX', 'XXXX']\n",
    "# df_words['Consumer complaint narrative'] = df['Consumer complaint narrative'].apply(lambda x: x.translate(None, ''.join(chars_to_remove)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_words = df['Consumer complaint narrative'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_labels = df['Company response to consumer'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = label_binarize(y_labels, classes=[0, 1, 2])\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2_train_words, X2_test_words, y2_train, y2_test = train_test_split(X_words, y, test_size=0.30, random_state=11)\n",
    "print X2_train_words.shape\n",
    "print X2_test_words.shape\n",
    "print y2_train.shape\n",
    "print y2_test.shape\n",
    "vectorizer = TfidfVectorizer(stop_words='english',lowercase=True, min_df=0.001, max_df = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_words_train = vectorizer.fit_transform(X2_train_words)\n",
    "X_words_test = vectorizer.transform(X2_test_words)  # DONT FIT_TRANSFORM THE TEST SET YOU NINNY.\n",
    "X_words_matrix = vectorizer.transform(X_words)\n",
    "\n",
    "\n",
    "print X_words_train.shape\n",
    "print X_words_test.shape\n",
    "print X_words_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_words_train\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbc = OneVsRestClassifier(RandomForestClassifier(n_estimators=500, n_jobs=-1, class_weight='auto'),n_jobs=-1)\n",
    "y2_score = nbc.fit(X_words_train, y2_train).predict_proba(X_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = nbc.score(X_words_test, y2_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y2_test[:, i],y2_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "label = ['Closed w/o Relief', 'Closed w/relief', 'Closed w/explaination']\n",
    "for i,v in enumerate(label):\n",
    "    plt.plot(fpr[i], tpr[i], label= v + ' (auc_area = {1:0.2f})'\n",
    "                                   ''.format(i, roc_auc[i]))\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity, Recall)')\n",
    "plt.title('ROC with non-text Features')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Word2Vec\n",
    "## Bag o' Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_words.shape\n",
    "df_words.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_words['Consumer complaint narrative'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example1 = BeautifulSoup(df_words['Consumer complaint narrative'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_words['Consumer complaint narrative'][0]\n",
    "print example1.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_review = review_to_words(df_words['Consumer complaint narrative'][0])\n",
    "print clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "print df_words['Consumer complaint narrative'].size\n",
    "num_reviews = df_words['Consumer complaint narrative'].size\n",
    "print num_reviews\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_reviews = []\n",
    "\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list \n",
    "print \"Cleaning and parsing the training set movie reviews...\\n\"\n",
    "clean_train_reviews = []\n",
    "for i in xrange( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % ( i+1, num_reviews )                                                                    \n",
    "    clean_train_reviews.append(review_to_words(df_words['Consumer complaint narrative'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Training the random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( train_data_features, df_words['Consumer complaint narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Word2Vec - Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from files \n",
    "train = pd.read_csv( \"labeledTrainData.tsv\", header=0, \n",
    " delimiter=\"\\t\", quoting=3 )\n",
    "test = pd.read_csv( \"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "unlabeled_train = pd.read_csv( \"unlabeledTrainData.tsv\", header=0, \n",
    " delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "# Verify the number of reviews that were read (100,000 in total)\n",
    "print \"Read %d labeled train reviews, %d labeled test reviews, \" \\\n",
    " \"and %d unlabeled reviews\\n\" % (train[\"review\"].size,  \n",
    " test[\"review\"].size, unlabeled_train[\"review\"].size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
