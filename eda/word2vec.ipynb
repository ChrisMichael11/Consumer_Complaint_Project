{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Consumer_Complaints_with_Consumer_Complaint_Narratives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_df_text(df):\n",
    "    \"\"\"\n",
    "    Take input df and get 'Consumer complaint narrative' (text features) for text\n",
    "    modeling.  Also create labels column 'Company response to consumer', with 3\n",
    "    categories.\n",
    "\n",
    "    INPUT - dataframe\n",
    "    OUTPUT - 'df_text' dataframe for use in modeling text features\n",
    "    \"\"\"\n",
    "\n",
    "    print \"Creating df_text for text feature modeling...\\n\"\n",
    "\n",
    "    df_text = pd.DataFrame()  # Create empty df to fill\n",
    "\n",
    "    df_text['Consumer complaint narrative'] = df['Consumer complaint narrative']\n",
    "\n",
    "    #  Create numerical values for 'Company response to consumer' and map to df\n",
    "    cust_resp_dict ={'Closed':0,\n",
    "                 'Untimely response':0,\n",
    "                 'Closed with explanation':0,\n",
    "                 'Closed with non-monetary relief':1,\n",
    "                 'Closed with monetary relief':1}\n",
    "\n",
    "    df_text['Company response to consumer'] = df['Company response to consumer'].apply(lambda x: cust_resp_dict[x])\n",
    "    print \"Successfully created df_text for non-text feature modeling!!!\\n\"\n",
    "\n",
    "    return df_text[1:10001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating df_text for text feature modeling...\n",
      "\n",
      "Successfully created df_text for non-text feature modeling!!!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company response to consumer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do n't know how they got my cell number. I t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I 'm a longtime member of Charter One Bank/RBS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After looking at my credit report, I saw a col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I received a call from a XXXX XXXX from XXXX @...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Was not contacted 4 years later about some pri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative  \\\n",
       "1  I do n't know how they got my cell number. I t...   \n",
       "2  I 'm a longtime member of Charter One Bank/RBS...   \n",
       "3  After looking at my credit report, I saw a col...   \n",
       "4  I received a call from a XXXX XXXX from XXXX @...   \n",
       "5  Was not contacted 4 years later about some pri...   \n",
       "\n",
       "   Company response to consumer  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             1  \n",
       "4                             0  \n",
       "5                             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_y(df):\n",
    "    \"\"\"\n",
    "    Split dataframe into X (text) and y (labels)\n",
    "    \"\"\"\n",
    "    X = df['Consumer complaint narrative'].tolist()\n",
    "    y = df['Company response to consumer'].tolist()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = get_X_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "model.index2word\n",
    "w2v = {w: vec for w, vec in zip(model.index2word, model.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mult_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])\n",
    "mult_nb_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"multinomial nb\", MultinomialNB())])\n",
    "bern_nb_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"bernoulli nb\", BernoulliNB())])\n",
    "# SVM - which is supposed to be more or less state of the art \n",
    "# http://www.cs.cornell.edu/people/tj/publications/joachims_98a.pdf\n",
    "svc = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "svc_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "# etree_glove_small = Pipeline([(\"glove vectorizer\", MeanEmbeddingVectorizer(glove_small)), \n",
    "#                         (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])\n",
    "# etree_glove_small_tfidf = Pipeline([(\"glove vectorizer\", TfidfEmbeddingVectorizer(glove_small)), \n",
    "#                         (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])\n",
    "# etree_glove_big = Pipeline([(\"glove vectorizer\", MeanEmbeddingVectorizer(glove_big)), \n",
    "#                         (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])\n",
    "# etree_glove_big_tfidf = Pipeline([(\"glove vectorizer\", TfidfEmbeddingVectorizer(glove_big)), \n",
    "#                         (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])\n",
    "\n",
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_models = [\n",
    "#     (\"mult_nb\", mult_nb),\n",
    "#     (\"mult_nb_tfidf\", mult_nb_tfidf),\n",
    "#     (\"bern_nb\", bern_nb),\n",
    "#     (\"bern_nb_tfidf\", bern_nb_tfidf),\n",
    "    (\"svc\", svc),\n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "#     (\"glove_small\", etree_glove_small), \n",
    "#     (\"glove_small_tfidf\", etree_glove_small_tfidf),\n",
    "#     (\"glove_big\", etree_glove_big), \n",
    "#     (\"glove_big_tfidf\", etree_glove_big),\n",
    "#     (\"w2v\", etree_w2v),\n",
    "#     (\"w2v_tfidf\", etree_w2v_tfidf),\n",
    "]\n",
    "scores = sorted([(name, cross_val_score(model, X, y, cv=5).mean()) \n",
    "                 for name, model in all_models], \n",
    "                key=lambda (_, x): -x)\n",
    "print tabulate(scores, floatfmt=\".4f\", headers=(\"model\", 'score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
