{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, MaxAbsScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from scipy import interp\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Consumer_Complaints_with_Consumer_Complaint_Narratives.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 'df_text' for text modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_df_text(df):\n",
    "    df_text = pd.DataFrame()  # Create empty df to fill\n",
    "    \n",
    "    df_text['Consumer complaint narrative'] = df['Consumer complaint narrative']\n",
    "    \n",
    "    cust_resp_dict ={'Closed':0,\n",
    "                 'Untimely response':0,\n",
    "                 'Closed with explanation':1,\n",
    "                 'Closed with non-monetary relief':2,\n",
    "                 'Closed with monetary relief':2}\n",
    "    \n",
    "    df_text['Company response to consumer'] = df['Company response to consumer'].apply(lambda x: cust_resp_dict[x])\n",
    "    \n",
    "    return df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company response to consumer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Received Capital One charge card offer XXXX. A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do n't know how they got my cell number. I t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I 'm a longtime member of Charter One Bank/RBS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After looking at my credit report, I saw a col...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I received a call from a XXXX XXXX from XXXX @...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Consumer complaint narrative  \\\n",
       "0  Received Capital One charge card offer XXXX. A...   \n",
       "1  I do n't know how they got my cell number. I t...   \n",
       "2  I 'm a longtime member of Charter One Bank/RBS...   \n",
       "3  After looking at my credit report, I saw a col...   \n",
       "4  I received a call from a XXXX XXXX from XXXX @...   \n",
       "\n",
       "   Company response to consumer  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             1  \n",
       "3                             2  \n",
       "4                             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_df_text(df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_text_data(df):\n",
    "    from sklearn.preprocessing import StandardScaler, label_binarize, MaxAbsScaler\n",
    "#     print df.head()\n",
    "    y_ = df['Company response to consumer']\n",
    "    y = label_binarize(y_, classes = [0, 1, 2])\n",
    "    n_classes=3 \n",
    "    y = y.sum(axis=1)\n",
    "    df.pop('Company response to consumer')\n",
    "    X = df.values\n",
    "    X = X.sum(axis=1)\n",
    "\n",
    "    print X.shape, y.shape\n",
    "    print y\n",
    "    print X\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84466,) (84466,)\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[ 'Received Capital One charge card offer XXXX. Applied, was accepted ( {$500.00} limit ), activated card and used for XXXX presents. Charge card # XXXX. Right after activating card ... Capital One sent me another card with same {$500.00} limit ... never activated ... never used that card. First bill from above card # came due XXXX and minimum payment due was {$15.00}. I sent in {$20.00} via USPMO and sent in before due date. With the XXXX non-activated, non used credit card ... ..they also sent me bill for some yearly fees when never even activated the card. So called them up ... ... .told them did not want the card and sent back to them. Well ... .get my next bill from the card # above ( XXXX ) ... .they did not credit me for the {$20.00} payment and charged me outrageous over the limit fees, late fees, etc ... and now {$70.00} payment due. So, I called up, their rep stated they accidentally applied my {$20.00} payment to wrong account number and would be corrected. So, I sent in a {$70.00} payment via USPMO along with note to make sure account corrected and both payments applied to correct account number ( minimum due and wanted to keep that card and also repair my credit from bankruptcy in XXXX or XXXX. ) So ... XXXX bill came in the mail ... .and once again ... ..they did not apply my payment of {$70.00}, nor the previous payment of {$20.00} ... .which they stated they would correct. They charged me more outrageous over the limit fees, late fees, etc, along with some stupid note about \" spreading yourself too thin. \\'\\' I thought wow ... .this is total bs ... ..so I called numerous times, wrote numerous times ... with no success of them correcting my account, when they acknowledged their mistake ( s ) ... ... then they wanted {$120.00} for minimum payment ... .I thought this is totally illegal. Sent my payments in on time and sent in more than minimum to even begin with. Kept calling and writing, with no resolution like they stated. I totally quit paying at that point ... Did not know what else to do at that time. Sometime around end of XXXX started getting threatening phone calls from some collection agency ... ... I mean really threatening. Like about every other day. Well, I ended up extremely ill, in and out of hospitals around that time, doctors, more hospitals, XXXX, XXXX, XXXX ... ..etc ... ..ended up in XXXX and XXXX entire summer, due to XXXX, XXXX ( XXXX at time ) XXXX ... XXXX, XXXX, and more ( Have all the records. ) Anyway ... come XXXX or XXXX, XXXX, XXXX, XXXX put a freeze on my bank account. ( currently XXXX XXXX ... Never knew took me to court & did an illegal Judgement. Called Capital One ... they new NOTHING ... Called XXXX etc..asked for verification XXXX XXXX ), etc..of my account, payments, court order, etc. Did receive back some info of my account. It clearly shows that they put my more than minimum payments onto a totally different account ... ..I now have the proof, of their illegal practices regarding Capital One and XXXX, XXXX and XXXX. I also have my stubs from my payments sent to them via USPMO for further proof. Now, just recently I have been calls at my home from unknown number stating to call XXXX stating something to the effect of ( my name ) and \" property at ( my home ) address \\'\\' being sent from the clerks office. My Mother, who is owner of this home, has also been getting such calls and days in row ... regarding me and the \" property at ( my home address. ) and clerk of court. Now she is the owner of this home which we rent ... and her property has nothing to do with my Capital One account which they totally illegally screwed me on..along with XXXX, XXXX XXXX XXXX illegal collection practices. So, I did look on website, and the Attorney for XXXX, XXXX, XXXX did do a Judgement renewal previous to us getting these harassing, threatening, illegal calls. Need help here. \\n'\n",
      " \"I do n't know how they got my cell number. I told them would deal onlybwith the original company and to stop harassing me. They called again after sending the do not contact messsage and told them I would report them. They have contacted people whose is of no concern my business. \\n\"\n",
      " 'I \\'m a longtime member of Charter One Bank/RBS Citizens Bank. When my mother ; XXXX XXXX became elderly, I assisted her in opening an account with Charter One at their branch office located on XXXX XXXX XXXX of XXXX in XXXX, Michigan and I was placed on her account as co-account owner. As my mother \\'s XXXX, it became necessary for me to obtain a \" Durable Power of Attorney \\'\\' to handle both her Financial and Medical needs. Some years ago, with my mother present, I presented the original ( stamped with seal ) \" Durable Power of Attorney \\'\\' at the Charter One branch office located on XXXX in XXXX, Michigan for their record file. When presented, it was my understanding I would be placed on all of my mother \\'s account. Furthermore, when I needed to transact her business I would be welcomed as though \" I \\'\\' were \" She. \\'\\' On XXXX XXXX, 2015, I was contacted by Charter One Master Card someone had made fraudulent charges on my mother \\'s credit card account. The caller stated she would immediately close my mother \\'s Master Credit Card account and open a new account and send another Master Card the next day. Upon receiving my mother \\'s new credit card I realized she was entitled to \" XXXX \\'\\' bonus points. I telephoned the bank to redeem her \" XXXX XXXX \\'\\' bonus points and I was informed my name was not on my mother \\'s credit card account. I informed them, I had taken the original \" Durable Power of Attorney \\'\\' into the branch office and it should be on file. The representative indicated there was a \" Durable Power of Attorney \\'\\' on file with Charter One Bank but Master Card is a separate entity from the bank and would require another \" Durable Power of Attorney. \\'\\' I replied why ca n\\'t Charter One forward a copy of the \" Durable Power of Attorney \\'\\' to Master Card. I was told to go into a local branch and they could resolve the issue. On XXXX XXXX, 2015, I went into the Charter One Bank located ; XXXX XXXX XXXX XXXX XXXX, in XXXX, Michigan, XXXX. I was told no branch manager was available - the bank teller made copies of \" Durable Power of Attorney \\'\\' and stated she would forward the document to the branch manager the following day to resolve the issue. On XXXX XXXX, 2015, I telephoned the XXXX branch for the results of their investigation and was told by an individual who identified himself as : XXXX, there were no branch managers available, but he had talked to representatives at banking headquarters and I would have to telephone \" customer service \\'\\' along with my mother on the telephone to resolve the issue. I informed him my mother is XXXX ( XXXX ) years old and suffers from \" XXXX XXXX XXXX \\'\\' and is XXXX of the issues involved. He offered a XXXX suggestion was to take the original \" Durable Power of Attorney \\'\\' into a local branch office for recording and to be placed on file. I indicated to him I had already done that years ago at the XXXX branch. XXXX indicated he was unable to resolve the matter at his level. In an effort to resolve the issue without further problems, on XXXX XXXX, 2015, I went to the branch office ; XXXX XXXX XXXX, XXXX, Michigan, XXXX and talked to XXXX XXXX. She indicated there was \" no \\'\\' branch manager available but she would assist me. She telephoned bank headquarters who told her there was \" no \\'\\' \" Durable Power of Attorney \\'\\' on file on my mother \\'s account. There are inconsistencies in the responses I received while trying to resolve this issue with Charter One Bank. I know I took the original \" Durable Power of Attorney \\'\\' to the Charter One Bank in XXXX, Michigan XXXX years ago to be placed on file for my mother \\'s banking accounts. This level of \" customer service \\'\\' is abysmal. \\n'\n",
      " ...,\n",
      " \"Equifax fails to remove the XXXX XXXX XXXX XXXX. account. Equifax reports incorrectly the date of first delinquency for removal. Equifax reports incorrectly that this account is scheduled to continue on my report past the statutory limits of the other major CRA 's even though I received a XXXX from XXXX XXXX XXXX XXXX. Equifax continues to report inaccurate information on my credit file which lowers my credit score. This causes me the inability to obtain credit and lowers my standards of living and causes me to languish and suffer.\"\n",
      " 'Today, I got an email from XXXXXXXXXXXX : if I ignored the BOFA letter, my account access could be suspended if I did not enter my email contact of bank record and the password to my email. It \\'s illegal : not just unethical solicitation of private/security information ; the bank is not allowed -- not entitled : not owed the information -- to demand I disclose my email of record password. I got an \\'alert \\' notice from BOFA in my email box too : when I logged into my account online, it said I needed to update my profile information or same thing as the email letter pdf except no request for email password. \\nI think either criminals knew BOFA sent real alerts for profile updates to BOFA customers, then quickly sent out their own criminal emails to try to steal passwords to email accounts of bank record or ... And in the meantime : BOFA is just fouling ; BOFA says I did not pay rent for the last six months on my bill pay page. BOFA did record XXXX XXXX rent refund XXXX {$1700.00} or that I paid it but not -- no XXXX XXXX refund : despite BOFA knowing full well I could not live at that residence or derived -0- benefit -- for XXXX XXXX, yet my account was debited [ I did pay the XXXX XXXX rent before I was locked at my home XXXX XXXX ] {$1700.00} for XXXX rent XXXX XXXX [ valid until XXXX XXXX, XXXX ]. And then [ complaint ( s ) XXXX ; XXXX ] BOFA IS NOT ALLOWED TO STEAL MONEY FROM ME BY SUPPOSEDLY PAYING NON-EXISTENT or even existent 3RD PARTIES : THE BANK CAN NOT DECIDE WHO OWES WHAT TO WHOM AND THEN STEAL MONEY FROM ME TO PAY THOSE FRAUDULENT BILLS FOR/AS/TO SUPPOSED OTHERS -- OWED OR NOT -- BY STEALING \\'LEGAL ORDER \\' MONEY FROM MY ACCOUNT ; it \\'s actually illegal for BOFA to garnish \" LEVY \\'\\' cash deposits and BOFA can never garnish for others -- IT \\'S A CRIME -- or even if BOFA was the legitimate garnishee. Any request for exception must first have a legitimate court order -- BOFA insanely told me to file for a court order and ask for exception to garnish my cash deposits : so, it was never filed in court -- that \\'s the only court record of just no levy/no garnishment. Because no one is allowed to request it EXCEPT : a person/entity requesting garnishment must file exception if having a CA State/US Federal judge issued court order : or not a never filed in court issued by an unidentifiable court clerk and/or no identity \" levying officer \\'\\' crime. State of CA/USA might allow exception for garnishment if it \\'s for child support/alimony but still not for \" levy \\'\\' or \" garnishment \\'\\' of cash deposits. NEVER : the money BOFA says BOFA stole was my XXXX XXXX XXXX rent refund XX/XX/XXXX-XX/XX/XXXX : BOFA IS NOT THE OWNER OF XXXX XXXX ; BOFA WAS NOT PROPERTY MANAGEMENT OF XXXX XXXX. BOFA ISSUED A LOAN TO XXXX XXXX HOA -- STOLE THE MONEY FROM THE HOA -- THEN DECLARED XXXX XXXX HOA IN DEFAULT AS BOFA \\'S ATTEMPT TO STEAL OF THE REAL ESTATE PROPERTY AND THE OVER {$60000.00} -- not the same money as my XXXX XXXX Apartment rent : not the same money I worked like a slave to earn/deposit into my Merrill Lynch accounts -- I \\'d already paid for XXXX XXXX rent ... At XXXX XXXX : I paid rent for XXXX XXXX XXXX \\' XXXX XXXX XXXX Condominiums from XX/XX/XXXX-XX/XX/XXXX and typically by POMO . All that \\'XXXX \\' rent money I earned/paid -- not the same money I \\'ve deposited at BOFA/ML -- is mostly likely still in an account for my name at XXXX XXXX , hence the XXXX recent check theft debacle. I did not open a WF account in my name during XX/XX/XXXX-XX/XX/XXXX : XXXX XXXX XXXX XXXX agent of process/property manager of XXXX XXXX XXXX Condos did it by using my identification information because I was the one working/earning/paying the money no one could really collect and once it added up to be the XXXX County declared purchase price of the condo, I was attacked at \\'XXXX \\'. At XXXX XXXX : {$40000.00} it was/is about. IRS : recent -- XXXX -- IRS complaint # XXXX {$2800.00} illegal debit XXXX.'\n",
      " 'Dear Sir/Madam, Around six months ago I opened Citigold checking account and I am still expecting XXXX XXXX XXXX miles to be posted for the promotion XXXX. On XXXX XXXX on my question XXXX XXXX replied that the investigation has been launched and I will get the outcome sent on my e-mail address which never happened. \\nBefore that on XXXX XXXX I have got a message XXXX from Citibank Client XXXX ( XXXX XXXX ) that my account has met the necessary requirements to qualify for this promotion and miles should be posted within 90 days which never happened. \\nBefore that on XXXX XXXX XXXX XXXX confirmed that promotion code XXXX attached to my Citigold account. \\nWhat Citibank is trying to do is pretty much scamming, trying not to meet commitments after all their acknowledgements that I was eligible. I carry out my obligations and pay account fee which is $ XXXX monthly and I want Citibank to provide good customer service as advertised and honor their promises.']\n"
     ]
    }
   ],
   "source": [
    "df_text = create_df_text(df)\n",
    "X, y = prep_text_data(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_split_function(X, y):\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=11)\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(X_train)\n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "#     from sklearn.utils import shuffle\n",
    "#     X_shuf, Y_shuf = shuffle(X_transformed, Y)\n",
    "\n",
    "\n",
    "#     vectorizer = TfidfVectorizer(stop_words='english',lowercase=True, min_df=0.001, max_df = 0.2)\n",
    "#     X_train = vectorizer.fit_transform(X_train)\n",
    "#     X_test = vectorizer.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_function(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59126,)\n",
      "(25340,)\n",
      "(59126,)\n",
      "(25340,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Kaggle Amazon Food Stuff\n",
    "https://www.kaggle.com/gpayen/d/snap/amazon-fine-food-reviews/building-a-prediction-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "To format our data and build the Term-doc incidence matrix, many operations will be performed on the data:\n",
    "\n",
    "•Stemming\n",
    "•Stop words removal\n",
    "•Lowering\n",
    "•Tokenization\n",
    "•Pruning (numbers and punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-494842d2161a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrantab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-494842d2161a>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#[line.decode('utf-8').strip() for line in title_file.readlines()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# tokens = [word for word in tokens if word not in stopwords.words('english')]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mstems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstem_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-494842d2161a>\u001b[0m in \u001b[0;36mstem_tokens\u001b[0;34m(tokens, stemmer)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstemmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mstemmed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstemmed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/nltk/stem/porter.pyc\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;31m## Define a stem() method that implements the StemmerI interface.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adjust_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/nltk/stem/porter.pyc\u001b[0m in \u001b[0;36mstem_word\u001b[0;34m(self, p, i, j)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step1ab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step1c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/nltk/stem/porter.pyc\u001b[0m in \u001b[0;36m_step1ab\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0med_or_ing_trimmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ied\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #[line.decode('utf-8').strip() for line in title_file.readlines()]\n",
    "    # tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return ' '.join(stems)\n",
    "\n",
    "from string import maketrans\n",
    "intab = string.punctuation\n",
    "outtab = \"                                \"\n",
    "trantab = maketrans(intab, outtab)\n",
    "\n",
    "## Training set\n",
    "corpus = []\n",
    "for text in X_train:\n",
    "    text = text.lower()\n",
    "    text = text.translate(trantab)\n",
    "    text = tokenize(text)\n",
    "    corpus.append(text)\n",
    "    \n",
    "count_vect = CountVectorizer(input=\"file\")\n",
    "X_train_counts = count_vect.fit_transform(corpus)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "## Testing set\n",
    "test_set = []\n",
    "for text in X_test:\n",
    "    text = text.lower()\n",
    "    text = text.translate(trantab)\n",
    "    text.tokenize(text)\n",
    "    test_set.append(text)\n",
    "    \n",
    "X_new_counts = count_vect.transform(test_set)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "from pandas import *\n",
    "prediction = dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Multinomial Naïve Bayes learning method¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "prediction['Multinomial'] = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Bernoulli Naïve Bayes learning method¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB().fit(X_train_tfidf, y_train)\n",
    "prediction['Bernoulli'] = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Logistic regression learning method¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "prediction['Logistic'] = logreg.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-615d21d2b451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "def formatt(x):\n",
    "    if x == 'negative':\n",
    "        return 0\n",
    "    return 1\n",
    "vfunc = np.vectorize(formatt)\n",
    "\n",
    "cmp = 0\n",
    "colors = ['b', 'g', 'y', 'm', 'k']\n",
    "for model, predicted in prediction.items():\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test.map(formatt), vfunc(predicted))\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    plt.plot(false_positive_rate, true_positive_rate, colors[cmp], label='%s: AUC %0.2f'% (model,roc_auc))\n",
    "    cmp += 1\n",
    "\n",
    "plt.title('Classifiers comparaison with ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, prediction['Logistic'], target_names = [\"positive\", \"negative\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cc143f0ebff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Compute confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Logistic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(set(Score)))\n",
    "    plt.xticks(tick_marks, set(Score), rotation=45)\n",
    "    plt.yticks(tick_marks, set(Score))\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, prediction['Logistic'])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm)    \n",
    "\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
